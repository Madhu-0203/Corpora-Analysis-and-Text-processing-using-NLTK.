{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NATURAL LANGUAGE PROCESSING - Corpora Analysis and Text processing using NLTK.**"
      ],
      "metadata": {
        "id": "yurnkm_hAjUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "XwsJvWcoBN5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7c545d-e26d-4d97-8f9c-5ffd0a722763"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Utilize Python NLTK (Natural Language Tool Kit) Platform and do the following.\n",
        "Install relevant Packages and Libraries (03 Marks)\n",
        "\n",
        "• Explore Brown Corpus and find the size, tokens, categories.\n",
        "\n",
        "• Find the size of word tokens?\n",
        "\n",
        "• Find the size of word types?\n",
        "\n",
        "• Find the size of the category “government”.\n",
        "\n",
        "• List the most frequent tokens.\n",
        "\n",
        "• Count the number of sentences.\n"
      ],
      "metadata": {
        "id": "Y9td0v_JAx7F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is Brown Corpus? \n",
        "The Brown Corpus of Standard American English was the first of the modern computer readable general corpara. The corpus consists of one million words of American English texts printed in 1961. \n",
        "\n",
        "Brown corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on... \n",
        "\n",
        "The actual brown corpus data is packaged as raw text files with IDs to identify them. "
      ],
      "metadata": {
        "id": "sLHMbxB9i0b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DOWNLOADING BROWN CORPUS**"
      ],
      "metadata": {
        "id": "lvOMl1zviqhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt \n",
        "import pandas as pd\n",
        "import math\n",
        "from nltk.corpus import brown\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "usdXDMdjhcXj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELd_YSxMlLRD",
        "outputId": "cc65d74f-4397-49e5-fd4d-889a70086a20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown.words())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoFSwzQ5jRy8",
        "outputId": "adb99bb4-9d23-4507-d8c5-2ccaf187c9b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161192"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown.sents())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOp2-SdXkIKg",
        "outputId": "84d79d25-2ad2-4765-9713-76ee57583045"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57340"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(brown.fileids('government'))\n",
        "#print(brown.raw('ca01').strip()[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtX_9nMtm42t",
        "outputId": "ab61089b-d96c-479c-ac77-dff8ba3d2619"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown.words()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gH-On0XiccK",
        "outputId": "dc84c316-a75b-40ec-ab9f-02699f624c95"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'Fulton',\n",
              " 'County',\n",
              " 'Grand',\n",
              " 'Jury',\n",
              " 'said',\n",
              " 'Friday',\n",
              " 'an',\n",
              " 'investigation',\n",
              " 'of']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "brown.sents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHJw9PkskDSD",
        "outputId": "692c6d20-e1f8-4a5e-c680-d14c398cdb01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysing the data before tokenization: \n",
        "\n",
        "By striping, \n",
        "\n",
        "Each word comes with a slash and a label.\n",
        "\n",
        "Punctuations are seperated from the word that comes before it. \n",
        "\n",
        "Each sentences is seperated by a newline. "
      ],
      "metadata": {
        "id": "LKzdLML8luc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(brown.raw('ca01').strip()[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zUGBNjSkMfm",
        "outputId": "31599100-3eae-4bfa-ce3e-7c7cf60b9e19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\n",
            "\n",
            "\n",
            "\tThe/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./np \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FREQUENCY OF WORDS: "
      ],
      "metadata": {
        "id": "tDPTYPSnYAmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_text = brown.words(categories='government')\n",
        "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
        "modals = ['can', 'could', 'may', 'might', 'must', 'will', 'government']\n",
        "\n",
        "for m in modals:\n",
        "  print(m + ':', fdist[m], end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4bTx7frYPMz",
        "outputId": "ba0381df-f147-45d5-ef17-1e300216a421"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can: 119 could: 38 may: 179 might: 13 must: 102 will: 244 government: 115 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Explore the corpora available in NLTK (any two) (02 Marks)\n",
        "\n",
        "• Raw corpus\n",
        "\n",
        "• POS tagged\n",
        "\n",
        "• Parsed\n",
        "\n",
        "• Multilingual aligned\n",
        "\n",
        "• Spoken language\n",
        "\n",
        "• Semantic tagged"
      ],
      "metadata": {
        "id": "YEhlAttiBOuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAW CORPUS "
      ],
      "metadata": {
        "id": "W36YG8DypF9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "print(brown.raw('ca01').strip()[:1000])"
      ],
      "metadata": {
        "id": "H9oQsTKWBmR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a8d3ce-440a-4248-d694-2c69788370c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\n",
            "\n",
            "\n",
            "\tThe/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./np \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS TAGGED"
      ],
      "metadata": {
        "id": "3ZfY004qpJz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using TaggedCorpusReader \n",
        "from nltk.corpus.reader import TaggedCorpusReader \n",
        "\n",
        "#Initializing \n",
        "x = TaggedCorpusReader('.', r'.*\\.pos')\n",
        "\n",
        "words = brown.raw('ca01')\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp_vUA60pRby",
        "outputId": "535bf4b6-4b04-4d63-bb6c-dae911cbe964"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\n",
            "\n",
            "\n",
            "\tThe/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./np ./.\n",
            "\n",
            "\n",
            "\t``/`` Only/rb a/at relative/jj handful/nn of/in such/jj reports/nns was/bedz received/vbn ''/'' ,/, the/at jury/nn said/vbd ,/, ``/`` considering/in the/at widespread/jj interest/nn in/in the/at election/nn ,/, the/at number/nn of/in voters/nns and/cc the/at size/nn of/in this/dt city/nn ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn said/vbd it/pps did/dod find/vb that/cs many/ap of/in Georgia's/np$ registration/nn and/cc election/nn laws/nns ``/`` are/ber outmoded/jj or/cc inadequate/jj and/cc often/rb ambiguous/jj ''/'' ./.\n",
            "\n",
            "\n",
            "\tIt/pps recommended/vbd that/cs Fulton/np legislators/nns act/vb ``/`` to/to have/hv these/dts laws/nns studied/vbn and/cc revised/vbn to/in the/at end/nn of/in modernizing/vbg and/cc improving/vbg them/ppo ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at grand/jj jury/nn commented/vbd on/in a/at number/nn of/in other/ap topics/nns ,/, among/in them/ppo the/at Atlanta/np and/cc Fulton/np-tl County/nn-tl purchasing/vbg departments/nns which/wdt it/pps said/vbd ``/`` are/ber well/ql operated/vbn and/cc follow/vb generally/rb accepted/vbn practices/nns which/wdt inure/vb to/in the/at best/jjt interest/nn of/in both/abx governments/nns ''/'' ./.\n",
            "\n",
            "\n",
            "\n",
            "Merger/nn-hl proposed/vbn-hl \n",
            "However/wrb ,/, the/at jury/nn said/vbd it/pps believes/vbz ``/`` these/dts two/cd offices/nns should/md be/be combined/vbn to/to achieve/vb greater/jjr efficiency/nn and/cc reduce/vb the/at cost/nn of/in administration/nn ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at City/nn-tl Purchasing/vbg-tl Department/nn-tl ,/, the/at jury/nn said/vbd ,/, ``/`` is/bez lacking/vbg in/in experienced/vbn clerical/jj personnel/nns as/cs a/at result/nn of/in city/nn personnel/nns policies/nns ''/'' ./.\n",
            "It/pps urged/vbd that/cs the/at city/nn ``/`` take/vb steps/nns to/to remedy/vb ''/'' this/dt problem/nn ./.\n",
            "\n",
            "\n",
            "\tImplementation/nn of/in Georgia's/np$ automobile/nn title/nn law/nn was/bedz also/rb recommended/vbn by/in the/at outgoing/jj jury/nn ./.\n",
            "\n",
            "\n",
            "\tIt/pps urged/vbd that/cs the/at next/ap Legislature/nn-tl ``/`` provide/vb enabling/vbg funds/nns and/cc re-set/vb the/at effective/jj date/nn so/cs that/cs an/at orderly/jj implementation/nn of/in the/at law/nn may/md be/be effected/vbn ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at grand/jj jury/nn took/vbd a/at swipe/nn at/in the/at State/nn-tl Welfare/nn-tl Department's/nn$-tl handling/nn of/in federal/jj funds/nns granted/vbn for/in child/nn welfare/nn services/nns in/in foster/jj homes/nns ./.\n",
            "\n",
            "\n",
            "\t``/`` This/dt is/bez one/cd of/in the/at major/jj items/nns in/in the/at Fulton/np-tl County/nn-tl general/jj assistance/nn program/nn ''/'' ,/, the/at jury/nn said/vbd ,/, but/cc the/at State/nn-tl Welfare/nn-tl Department/nn-tl ``/`` has/hvz seen/vbn fit/jj to/to distribute/vb these/dts funds/nns through/in the/at welfare/nn departments/nns of/in all/abn the/at counties/nns in/in the/at state/nn with/in the/at exception/nn of/in Fulton/np-tl County/nn-tl ,/, which/wdt receives/vbz none/pn of/in this/dt money/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at jurors/nns said/vbd they/ppss realize/vb ``/`` a/at proportionate/jj distribution/nn of/in these/dts funds/nns might/md disable/vb this/dt program/nn in/in our/pp$ less/ql populous/jj counties/nns ''/'' ./.\n",
            "\n",
            "\n",
            "\tNevertheless/rb ,/, ``/`` we/ppss feel/vb that/cs in/in the/at future/nn Fulton/np-tl County/nn-tl should/md receive/vb some/dti portion/nn of/in these/dts available/jj funds/nns ''/'' ,/, the/at jurors/nns said/vbd ./.\n",
            "``/`` Failure/nn to/to do/do this/dt will/md continue/vb to/to place/vb a/at disproportionate/jj burden/nn ''/'' on/in Fulton/np taxpayers/nns ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn also/rb commented/vbd on/in the/at Fulton/np ordinary's/nn$ court/nn which/wdt has/hvz been/ben under/in fire/nn for/in its/pp$ practices/nns in/in the/at appointment/nn of/in appraisers/nns ,/, guardians/nns and/cc administrators/nns and/cc the/at awarding/nn of/in fees/nns and/cc compensation/nn ./.\n",
            "\n",
            "\n",
            "\n",
            "Wards/nns-hl protected/vbn-hl \n",
            "The/at jury/nn said/vbd it/pps found/vbd the/at court/nn ``/`` has/hvz incorporated/vbn into/in its/pp$ operating/vbg procedures/nns the/at recommendations/nns ''/'' of/in two/cd previous/jj grand/jj juries/nns ,/, the/at Atlanta/np-tl Bar/nn-tl Association/nn-tl and/cc an/at interim/nn citizens/nns committee/nn ./.\n",
            "\n",
            "\n",
            "\t``/`` These/dts actions/nns should/md serve/vb to/to protect/vb in/in fact/nn and/cc in/in effect/nn the/at court's/nn$ wards/nns from/in undue/jj costs/nns and/cc its/pp$ appointed/vbn and/cc elected/vbn servants/nns from/in unmeritorious/jj criticisms/nns ''/'' ,/, the/at jury/nn said/vbd ./.\n",
            "\n",
            "\n",
            "\tRegarding/in Atlanta's/np$ new/jj multi-million-dollar/jj airport/nn ,/, the/at jury/nn recommended/vbd ``/`` that/cs when/wrb the/at new/jj management/nn takes/vbz charge/nn Jan./np 1/cd the/at airport/nn be/be operated/vbn in/in a/at manner/nn that/wps will/md eliminate/vb political/jj influences/nns ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn did/dod not/* elaborate/vb ,/, but/cc it/pps added/vbd that/cs ``/`` there/ex should/md be/be periodic/jj surveillance/nn of/in the/at pricing/vbg practices/nns of/in the/at concessionaires/nns for/in the/at purpose/nn of/in keeping/vbg the/at prices/nns reasonable/jj ''/'' ./.\n",
            "\n",
            "\n",
            "\n",
            "Ask/vb-hl jail/nn-hl deputies/nns-hl \n",
            "On/in other/ap matters/nns ,/, the/at jury/nn recommended/vbd that/cs :/: (/( 1/cd )/) \n",
            "Four/cd additional/jj deputies/nns be/be employed/vbn at/in the/at Fulton/np-tl County/nn-tl Jail/nn-tl and/cc ``/`` a/at doctor/nn ,/, medical/jj intern/nn or/cc extern/nn be/be employed/vbn for/in night/nn and/cc weekend/nn duty/nn at/in the/at jail/nn ''/'' ./.\n",
            "(/( 2/cd )/) \n",
            "Fulton/np legislators/nns ``/`` work/vb with/in city/nn officials/nns to/to pass/vb enabling/vbg legislation/nn that/wps will/md permit/vb the/at establishment/nn of/in a/at fair/jj and/cc equitable/jj ''/'' pension/nn plan/nn for/in city/nn employes/nns ./.\n",
            "\n",
            "\n",
            "\tThe/at jury/nn praised/vbd the/at administration/nn and/cc operation/nn of/in the/at Atlanta/np-tl Police/nns-tl Department/nn-tl ,/, the/at Fulton/np-tl Tax/nn-tl Commissioner's/nn$-tl Office/nn-tl ,/, the/at Bellwood/np and/cc Alpharetta/np prison/nn farms/nns ,/, Grady/np-tl Hospital/nn-tl and/cc the/at Fulton/np-tl Health/nn-tl Department/nn-tl ./.\n",
            "\n",
            "\n",
            "\tMayor/nn-tl William/np B./np Hartsfield/np filed/vbd suit/nn for/in divorce/nn from/in his/pp$ wife/nn ,/, Pearl/np Williams/np Hartsfield/np ,/, in/in Fulton/np-tl Superior/jj-tl Court/nn-tl Friday/nr ./.\n",
            "His/pp$ petition/nn charged/vbd mental/jj cruelty/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at couple/nn was/bedz married/vbn Aug./np 2/cd ,/, 1913/cd ./.\n",
            "They/ppss have/hv a/at son/nn ,/, William/np Berry/np Jr./np ,/, and/cc a/at daughter/nn ,/, Mrs./np J./np M./np Cheshire/np of/in Griffin/np ./.\n",
            "\n",
            "\n",
            "\tAttorneys/nns for/in the/at mayor/nn said/vbd that/cs an/at amicable/jj property/nn settlement/nn has/hvz been/ben agreed/vbn upon/rb ./.\n",
            "\n",
            "\n",
            "\tThe/at petition/nn listed/vbd the/at mayor's/nn$ occupation/nn as/cs ``/`` attorney/nn ''/'' and/cc his/pp$ age/nn as/cs 71/cd ./.\n",
            "It/pps listed/vbd his/pp$ wife's/nn$ age/nn as/cs 74/cd and/cc place/nn of/in birth/nn as/cs Opelika/np ,/, Ala./np ./.\n",
            "\n",
            "\n",
            "\tThe/at petition/nn said/vbd that/cs the/at couple/nn has/hvz not/* lived/vbn together/rb as/cs man/nn and/cc wife/nn for/in more/ap than/in a/at year/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at Hartsfield/np home/nr is/bez at/in 637/cd E./np Pelham/np Rd./nn-tl Aj/nn ./.\n",
            "\n",
            "\n",
            "\tHenry/np L./np Bowden/np was/bedz listed/vbn on/in the/at petition/nn as/cs the/at mayor's/nn$ attorney/nn ./.\n",
            "\n",
            "\n",
            "\tHartsfield/np has/hvz been/ben mayor/nn of/in Atlanta/np ,/, with/in exception/nn of/in one/cd brief/jj interlude/nn ,/, since/in 1937/cd ./.\n",
            "His/pp$ political/jj career/nn goes/vbz back/rb to/in his/pp$ election/nn to/in city/nn council/nn in/in 1923/cd ./.\n",
            "\n",
            "\n",
            "\tThe/at mayor's/nn$ present/jj term/nn of/in office/nn expires/vbz Jan./np 1/cd ./.\n",
            "He/pps will/md be/be succeeded/vbn by/in Ivan/np Allen/np Jr./np ,/, who/wps became/vbd a/at candidate/nn in/in the/at Sept./np 13/cd primary/nn after/cs Mayor/nn-tl Hartsfield/np announced/vbd that/cs he/pps would/md not/* run/vb for/in reelection/nn ./.\n",
            "\n",
            "\n",
            "\tGeorgia/np Republicans/nps are/ber getting/vbg strong/jj encouragement/nn to/to enter/vb a/at candidate/nn in/in the/at 1962/cd governor's/nn$ race/nn ,/, a/at top/jjs official/nn said/vbd Wednesday/nr ./.\n",
            "\n",
            "\n",
            "\tRobert/np Snodgrass/np ,/, state/nn GOP/nn chairman/nn ,/, said/vbd a/at meeting/nn held/vbn Tuesday/nr night/nn in/in Blue/jj-tl Ridge/nn-tl brought/vbd enthusiastic/jj responses/nns from/in the/at audience/nn ./.\n",
            "\n",
            "\n",
            "\tState/nn-tl Party/nn-tl Chairman/nn-tl James/np W./np Dorsey/np added/vbd that/cs enthusiasm/nn was/bedz picking/vbg up/rp for/in a/at state/nn rally/nn to/to be/be held/vbn Sept./np 8/cd in/in Savannah/np at/in which/wdt newly/rb elected/vbn Texas/np Sen./nn-tl John/np Tower/np will/md be/be the/at featured/vbn speaker/nn ./.\n",
            "\n",
            "\n",
            "\tIn/in the/at Blue/jj-tl Ridge/nn-tl meeting/nn ,/, the/at audience/nn was/bedz warned/vbn that/cs entering/vbg a/at candidate/nn for/in governor/nn would/md force/vb it/ppo to/to take/vb petitions/nns out/rp into/in voting/vbg precincts/nns to/to obtain/vb the/at signatures/nns of/in registered/vbn voters/nns ./.\n",
            "\n",
            "\n",
            "\tDespite/in the/at warning/vbg ,/, there/ex was/bedz a/at unanimous/jj vote/nn to/to enter/vb a/at candidate/nn ,/, according/in to/in Republicans/nps who/wps attended/vbd ./.\n",
            "\n",
            "\n",
            "\tWhen/wrb the/at crowd/nn was/bedz asked/vbn whether/cs it/pps wanted/vbd to/to wait/vb one/cd more/ap term/nn to/to make/vb the/at race/nn ,/, it/pps voted/vbd no/rb --/-- and/cc there/ex were/bed no/at dissents/nns ./.\n",
            "\n",
            "\n",
            "\tThe/at largest/jjt hurdle/nn the/at Republicans/nps would/md have/hv to/to face/vb is/bez a/at state/nn law/nn which/wdt says/vbz that/cs before/cs making/vbg a/at first/od race/nn ,/, one/cd of/in two/cd alternative/jj courses/nns must/md be/be taken/vbn :/: 1/cd \n",
            "Five/cd per/in cent/nn of/in the/at voters/nns in/in each/dt county/nn must/md sign/vb petitions/nns requesting/vbg that/cs the/at Republicans/nps be/be allowed/vbn to/to place/vb names/nns of/in candidates/nns on/in the/at general/jj election/nn ballot/nn ,/, or/cc 2/cd \n",
            "The/at Republicans/nps must/md hold/vb a/at primary/nn under/in the/at county/nn unit/nn system/nn --/-- a/at system/nn which/wdt the/at party/nn opposes/vbz in/in its/pp$ platform/nn ./.\n",
            "\n",
            "\n",
            "\tSam/np Caldwell/np ,/, State/nn-tl Highway/nn-tl Department/nn-tl public/jj relations/nns director/nn ,/, resigned/vbd Tuesday/nr to/to work/vb for/in Lt./nn-tl Gov./nn-tl Garland/np Byrd's/np$ campaign/nn ./.\n",
            "\n",
            "\n",
            "\tCaldwell's/np$ resignation/nn had/hvd been/ben expected/vbn for/in some/dti time/nn ./.\n",
            "He/pps will/md be/be succeeded/vbn by/in Rob/np Ledford/np of/in Gainesville/np ,/, who/wps has/hvz been/ben an/at assistant/nn more/ap than/in three/cd years/nns ./.\n",
            "When/wrb the/at gubernatorial/jj campaign/nn starts/vbz ,/, Caldwell/np is/bez expected/vbn to/to become/vb a/at campaign/nn coordinator/nn for/in Byrd/np ./.\n",
            "\n",
            "\n",
            "\tThe/at Georgia/np-tl Legislature/nn-tl will/md wind/vb up/rp its/pp$ 1961/cd session/nn Monday/nr and/cc head/vb for/in home/nr --/-- where/wrb some/dti of/in the/at highway/nn bond/nn money/nn it/pps approved/vbd will/md follow/vb shortly/rb ./.\n",
            "\n",
            "\n",
            "\tBefore/in adjournment/nn Monday/nr afternoon/nn ,/, the/at Senate/nn-tl is/bez expected/vbn to/to approve/vb a/at study/nn of/in the/at number/nn of/in legislators/nns allotted/vbn to/in rural/jj and/cc urban/jj areas/nns to/to determine/vb what/wdt adjustments/nns should/md be/be made/vbn ./.\n",
            "\n",
            "\n",
            "\tGov./nn-tl Vandiver/np is/bez expected/vbn to/to make/vb the/at traditional/jj visit/nn to/in both/abx chambers/nns as/cs they/ppss work/vb toward/in adjournment/nn ./.\n",
            "Vandiver/np likely/rb will/md mention/vb the/at $100/nns million/cd highway/nn bond/nn issue/nn approved/vbn earlier/rbr in/in the/at session/nn as/cs his/pp$ first/od priority/nn item/nn ./.\n",
            "\n",
            "\n",
            "\n",
            "Construction/nn-hl bonds/nns-hl \n",
            "Meanwhile/rb ,/, it/pps was/bedz learned/vbn the/at State/nn-tl Highway/nn-tl Department/nn-tl is/bez very/ql near/rb being/beg ready/jj to/to issue/vb the/at first/od $30/nns million/cd worth/nn of/in highway/nn reconstruction/nn bonds/nns ./.\n",
            "\n",
            "\n",
            "\tThe/at bond/nn issue/nn will/md go/vb to/in the/at state/nn courts/nns for/in a/at friendly/jj test/nn suit/nn to/to test/vb the/at validity/nn of/in the/at act/nn ,/, and/cc then/rb the/at sales/nns will/md begin/vb and/cc contracts/nns let/vbn for/in repair/nn work/nn on/in some/dti of/in Georgia's/np$ most/ql heavily/rb traveled/vbn highways/nns ./.\n",
            "\n",
            "\n",
            "\tA/at Highway/nn-tl Department/nn-tl source/nn said/vbd there/ex also/rb is/bez a/at plan/nn there/rb to/to issue/vb some/dti $3/nns million/cd to/in $4/nns million/cd worth/nn of/in Rural/jj-tl Roads/nns-tl Authority/nn-tl bonds/nns for/in rural/jj road/nn construction/nn work/nn ./.\n",
            "\n",
            "\n",
            "\n",
            "A/at-hl revolving/vbg-hl fund/nn-hl \n",
            "The/at department/nn apparently/rb intends/vbz to/to make/vb the/at Rural/jj-tl Roads/nns-tl Authority/nn-tl a/at revolving/vbg fund/nn under/in which/wdt new/jj bonds/nns would/md be/be issued/vbn every/at time/nn a/at portion/nn of/in the/at old/jj ones/nns are/ber paid/vbn off/rp by/in tax/nn authorities/nns ./.\n",
            "\n",
            "\n",
            "\tVandiver/np opened/vbd his/pp$ race/nn for/in governor/nn in/in 1958/cd with/in a/at battle/nn in/in the/at Legislature/nn-tl against/in the/at issuance/nn of/in $50/nns million/cd worth/nn of/in additional/jj rural/jj roads/nns bonds/nns proposed/vbn by/in then/rb Gov./nn-tl Marvin/np Griffin/np ./.\n",
            "\n",
            "\n",
            "\tThe/at Highway/nn-tl Department/nn-tl source/nn told/vbd The/at-tl Constitution/nn-tl ,/, however/wrb ,/, that/cs Vandiver/np has/hvz not/* been/ben consulted/vbn yet/rb about/in the/at plans/nns to/to issue/vb the/at new/jj rural/jj roads/nns bonds/nns ./.\n",
            "\n",
            "\n",
            "\tSchley/np County/nn-tl Rep./nn-tl B./np D./np Pelham/np will/md offer/vb a/at resolution/nn Monday/nr in/in the/at House/nn-tl to/to rescind/vb the/at body's/nn$ action/nn of/in Friday/nr in/in voting/vbg itself/ppl a/at $10/nns per/in day/nn increase/nn in/in expense/nn allowances/nns ./.\n",
            "\n",
            "\n",
            "\tPelham/np said/vbd Sunday/nr night/nn there/ex was/bedz research/nn being/beg done/vbn on/in whether/cs the/at ``/`` quickie/nn ''/'' vote/nn on/in the/at increase/nn can/md be/be repealed/vbn outright/rb or/cc whether/cs notice/nn would/md have/hv to/to first/rb be/be given/vbn that/cs reconsideration/nn of/in the/at action/nn would/md be/be sought/vbn ./.\n",
            "\n",
            "\n",
            "\tWhile/cs emphasizing/vbg that/cs technical/jj details/nns were/bed not/* fully/rb worked/vbn out/rp ,/, Pelham/np said/vbd his/pp$ resolution/nn would/md seek/vb to/to set/vb aside/rb the/at privilege/nn resolution/nn which/wdt the/at House/nn-tl voted/vbd through/in 87-31/cd ./.\n",
            "\n",
            "\n",
            "\tA/at similar/jj resolution/nn passed/vbd in/in the/at Senate/nn-tl by/in a/at vote/nn of/in 29-5/cd ./.\n",
            "As/in of/in Sunday/nr night/nn ,/, there/ex was/bedz no/at word/nn of/in a/at resolution/nn being/beg offered/vbn there/rb to/to rescind/vb the/at action/nn ./.\n",
            "\n",
            "\n",
            "\tPelham/np pointed/vbd out/rp that/cs Georgia/np voters/nns last/ap November/np rejected/vbd a/at constitutional/jj amendment/nn to/to allow/vb legislators/nns to/to vote/vb on/in pay/nn raises/nns for/in future/jj Legislature/nn-tl sessions/nns ./.\n",
            "\n",
            "\n",
            "\tA/at veteran/jj Jackson/np-tl County/nn-tl legislator/nn will/md ask/vb the/at Georgia/np-tl House/nn-tl Monday/nr to/to back/vb federal/jj aid/nn to/in education/nn ,/, something/pn it/pps has/hvz consistently/rb opposed/vbn in/in the/at past/nn ./.\n",
            "\n",
            "\n",
            "\tRep./nn-tl Mac/np Barber/np of/in Commerce/nn-tl is/bez asking/vbg the/at House/nn-tl in/in a/at privilege/nn resolution/nn to/to ``/`` endorse/vb increased/vbn federal/jj support/nn for/in public/jj education/nn ,/, provided/vbn that/cs such/jj funds/nns be/be received/vbn and/cc expended/vbn ''/'' as/cs state/nn funds/nns ./.\n",
            "\n",
            "\n",
            "\tBarber/np ,/, who/wps is/bez in/in his/pp$ 13th/od year/nn as/cs a/at legislator/nn ,/, said/vbd there/ex ``/`` are/ber some/dti members/nns of/in our/pp$ congressional/jj delegation/nn in/in Washington/np who/wps would/md like/vb to/to see/vb it/ppo (/( the/at resolution/nn )/) passed/vbn ''/'' ./.\n",
            "But/cc he/pps added/vbd that/cs none/pn of/in Georgia's/np$ congressmen/nns specifically/rb asked/vbd him/ppo to/to offer/vb the/at resolution/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at resolution/nn ,/, which/wdt Barber/np tossed/vbd into/in the/at House/nn-tl hopper/nn Friday/nr ,/, will/md be/be formally/rb read/vbn Monday/nr ./.\n",
            "It/pps says/vbz that/cs ``/`` in/in the/at event/nn Congress/np does/doz provide/vb this/dt increase/nn in/in federal/jj funds/nns ''/'' ,/, the/at State/nn-tl Board/nn-tl of/in-tl Education/nn-tl should/md be/be directed/vbn to/to ``/`` give/vb priority/nn ''/'' to/in teacher/nn pay/nn raises/nns ./.\n",
            "Colquitt/np-hl \n",
            "--/-- After/in a/at long/jj ,/, hot/jj controversy/nn ,/, Miller/np-tl County/nn-tl has/hvz a/at new/jj school/nn superintendent/nn ,/, elected/vbn ,/, as/cs a/at policeman/nn put/vbd it/ppo ,/, in/in the/at ``/`` coolest/jjt election/nn I/ppss ever/rb saw/vbd in/in this/dt county/nn ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at new/jj school/nn superintendent/nn is/bez Harry/np Davis/np ,/, a/at veteran/jj agriculture/nn teacher/nn ,/, who/wps defeated/vbd Felix/np Bush/np ,/, a/at school/nn principal/nn and/cc chairman/nn of/in the/at Miller/np-tl County/nn-tl Democratic/jj-tl Executive/jj-tl Committee/nn-tl ./.\n",
            "\n",
            "\n",
            "\tDavis/np received/vbd 1,119/cd votes/nns in/in Saturday's/nr$ election/nn ,/, and/cc Bush/np got/vbd 402/cd ./.\n",
            "Ordinary/nn-tl Carey/np Williams/np ,/, armed/vbn with/in a/at pistol/nn ,/, stood/vbd by/in at/in the/at polls/nns to/to insure/vb order/nn ./.\n",
            "\n",
            "\n",
            "\t``/`` This/dt was/bedz the/at coolest/jjt ,/, calmest/jjt election/nn I/ppss ever/rb saw/vbd ''/'' ,/, Colquitt/np-tl Policeman/nn-tl Tom/np Williams/np said/vbd ./.\n",
            "``/`` Being/beg at/in the/at polls/nns was/bedz just/rb like/cs being/beg at/in church/nn ./.\n",
            "I/ppss didn't/dod* smell/vb a/at drop/nn of/in liquor/nn ,/, and/cc we/ppss didn't/dod* have/hv a/at bit/nn of/in trouble/nn ''/'' ./.\n",
            "\n",
            "\n",
            "\tThe/at campaign/nn leading/vbg to/in the/at election/nn was/bedz not/* so/ql quiet/jj ,/, however/wrb ./.\n",
            "It/pps was/bedz marked/vbn by/in controversy/nn ,/, anonymous/jj midnight/nn phone/nn calls/nns and/cc veiled/vbn threats/nns of/in violence/nn ./.\n",
            "\n",
            "\n",
            "\tThe/at former/ap county/nn school/nn superintendent/nn ,/, George/np P./np Callan/np ,/, shot/vbd himself/ppl to/in death/nn March/np 18/cd ,/, four/cd days/nns after/cs he/pps resigned/vbd his/pp$ post/nn in/in a/at dispute/nn with/in the/at county/nn school/nn board/nn ./.\n",
            "\n",
            "\n",
            "\tDuring/in the/at election/nn campaign/nn ,/, both/abx candidates/nns ,/, Davis/np and/cc Bush/np ,/, reportedly/rb received/vbd anonymous/jj telephone/nn calls/nns ./.\n",
            "Ordinary/nn-tl Williams/np said/vbd he/pps ,/, too/rb ,/, was/bedz subjected/vbn to/in anonymous/jj calls/nns soon/rb after/cs he/pps scheduled/vbd the/at election/nn ./.\n",
            "\n",
            "\n",
            "\tMany/ap local/jj citizens/nns feared/vbd that/cs there/ex would/md be/be irregularities/nns at/in the/at polls/nns ,/, and/cc Williams/np got/vbd himself/ppl a/at permit/nn to/to carry/vb a/at gun/nn and/cc promised/vbd an/at orderly/jj election/nn ./.\n",
            "\n",
            "\n",
            "\tSheriff/nn-tl Felix/np Tabb/np said/vbd the/at ordinary/nn apparently/rb made/vbd good/jj his/pp$ promise/nn ./.\n",
            "\n",
            "\n",
            "\t``/`` Everything/pn went/vbd real/ql smooth/jj ''/'' ,/, the/at sheriff/nn said/vbd ./.\n",
            "``/`` There/ex wasn't/bedz* a/at bit/nn of/in trouble/nn ''/'' ./.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Create a text corpus with a minimum of 200 words (unique content). Implement the following text processing (05 Marks)\n",
        "\n",
        "• Word segmentation\n",
        "\n",
        "• Sentence segmentation\n",
        "\n",
        "• Convert to Lowercase\n",
        "\n",
        "• Stop words removal\n",
        "\n",
        "• Stemming\n",
        "\n",
        "• Lemmatization\n",
        "\n",
        "• Part of speech tagger"
      ],
      "metadata": {
        "id": "8HjnYRugBZEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Corpus: Movie Description:\n",
        "\n",
        " \n",
        "The Fault in Our Stars book and subsequent movie written by John Green were inspired in part by Esther Earl. Esther Earl was the author’s friend. The lead character Hazel in the movie was inspired by the Author’s friendship with Esther Earl and his affection for her family and friends. The superficial concept of oxygen tubes and thyroid cancer was from Esther’s life. She died of thyroid cancer on August 25, 2010, at age sixteen.\n",
        "\n",
        "Esther’s unusual mix of teenagers and empathy inspired the author the most. She was a very outwardly focused person, very conscious of and attentive to her friends and family, but she was also silly and funny and totally normal. The Author didn’t appropriate Esther's story, which belongs to her and to her family and not to me. Hazel is a fictional character, and she is in many important ways very different from the person Esther was.\n"
      ],
      "metadata": {
        "id": "r8jfddv1CR3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The Fault in Our Stars book and subsequent movie written by John Green were inspired in part by Esther Earl. Esther Earl was the author’s friend. The lead character Hazel in the movie was inspired by the Author’s friendship with Esther Earl and his affection for her family and friends. The superficial concept of oxygen tubes and thyroid cancer was from Esther’s life. She died of thyroid cancer on August 25, 2010, at age sixteen. Esther’s unusual mix of teenagers and empathy inspired the author the most. She was a very outwardly focused person, very conscious of and attentive to her friends and family, but she was also silly and funny and totally normal. The Author didn’t appropriate Esther's story, which belongs to her and to her family and not to me. Hazel is a fictional character, and she is in many important ways very different from the person Esther was.\"\n",
        "len(text)"
      ],
      "metadata": {
        "id": "oPjBbjT6A3yU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e1ce75b-ccc0-4ba3-9af6-8d9967b81cbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "870"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All Lower cases"
      ],
      "metadata": {
        "id": "r3zmInK0NQfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_lowercase = text.lower()\n",
        "print(text_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-LVxaLAuF_D",
        "outputId": "fb698701-014f-4a1f-bf45-b16de2030957"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the fault in our stars book and subsequent movie written by john green were inspired in part by esther earl. esther earl was the author’s friend. the lead character hazel in the movie was inspired by the author’s friendship with esther earl and his affection for her family and friends. the superficial concept of oxygen tubes and thyroid cancer was from esther’s life. she died of thyroid cancer on august 25, 2010, at age sixteen. esther’s unusual mix of teenagers and empathy inspired the author the most. she was a very outwardly focused person, very conscious of and attentive to her friends and family, but she was also silly and funny and totally normal. the author didn’t appropriate esther's story, which belongs to her and to her family and not to me. hazel is a fictional character, and she is in many important ways very different from the person esther was.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Segmentation"
      ],
      "metadata": {
        "id": "dIeqvTGTNU87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sentences = nltk.sent_tokenize(text_lowercase)\n",
        "print(text_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_42Eo6a4Mf27",
        "outputId": "b882115c-477b-435e-9f66-fe3907cbac87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the fault in our stars book and subsequent movie written by john green were inspired in part by esther earl.', 'esther earl was the author’s friend.', 'the lead character hazel in the movie was inspired by the author’s friendship with esther earl and his affection for her family and friends.', 'the superficial concept of oxygen tubes and thyroid cancer was from esther’s life.', 'she died of thyroid cancer on august 25, 2010, at age sixteen.', 'esther’s unusual mix of teenagers and empathy inspired the author the most.', 'she was a very outwardly focused person, very conscious of and attentive to her friends and family, but she was also silly and funny and totally normal.', \"the author didn’t appropriate esther's story, which belongs to her and to her family and not to me.\", 'hazel is a fictional character, and she is in many important ways very different from the person esther was.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Segmentation"
      ],
      "metadata": {
        "id": "1j1vu9TjOFgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens = [nltk.tokenize.word_tokenize(sent) for sent in text_sentences]\n",
        "\n",
        "for token in text_tokens:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TTN8FZOHTc",
        "outputId": "eb97277b-77c5-460a-af49-4f30ad414f71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'fault', 'in', 'our', 'stars', 'book', 'and', 'subsequent', 'movie', 'written', 'by', 'john', 'green', 'were', 'inspired', 'in', 'part', 'by', 'esther', 'earl', '.']\n",
            "['esther', 'earl', 'was', 'the', 'author', '’', 's', 'friend', '.']\n",
            "['the', 'lead', 'character', 'hazel', 'in', 'the', 'movie', 'was', 'inspired', 'by', 'the', 'author', '’', 's', 'friendship', 'with', 'esther', 'earl', 'and', 'his', 'affection', 'for', 'her', 'family', 'and', 'friends', '.']\n",
            "['the', 'superficial', 'concept', 'of', 'oxygen', 'tubes', 'and', 'thyroid', 'cancer', 'was', 'from', 'esther', '’', 's', 'life', '.']\n",
            "['she', 'died', 'of', 'thyroid', 'cancer', 'on', 'august', '25', ',', '2010', ',', 'at', 'age', 'sixteen', '.']\n",
            "['esther', '’', 's', 'unusual', 'mix', 'of', 'teenagers', 'and', 'empathy', 'inspired', 'the', 'author', 'the', 'most', '.']\n",
            "['she', 'was', 'a', 'very', 'outwardly', 'focused', 'person', ',', 'very', 'conscious', 'of', 'and', 'attentive', 'to', 'her', 'friends', 'and', 'family', ',', 'but', 'she', 'was', 'also', 'silly', 'and', 'funny', 'and', 'totally', 'normal', '.']\n",
            "['the', 'author', 'didn', '’', 't', 'appropriate', 'esther', \"'s\", 'story', ',', 'which', 'belongs', 'to', 'her', 'and', 'to', 'her', 'family', 'and', 'not', 'to', 'me', '.']\n",
            "['hazel', 'is', 'a', 'fictional', 'character', ',', 'and', 'she', 'is', 'in', 'many', 'important', 'ways', 'very', 'different', 'from', 'the', 'person', 'esther', 'was', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS Tagging and Occurrances of the Tags"
      ],
      "metadata": {
        "id": "38V9CMl8NK4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter \n",
        "tokens = nltk.word_tokenize(text_lowercase)\n",
        "tags = nltk.pos_tag(tokens)\n",
        "print(\"POS Tagging of all the words:\")\n",
        "print(tags)\n",
        "print(\" \")\n",
        "\n",
        "print(\"Count the occurance of the POS:\")\n",
        "counts = Counter(tag for word, tag in tags)\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ureGzoa0uSWU",
        "outputId": "499a244c-87cc-4c6e-9ed8-ed3179b640a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POS Tagging of all the words:\n",
            "[('the', 'DT'), ('fault', 'NN'), ('in', 'IN'), ('our', 'PRP$'), ('stars', 'NNS'), ('book', 'NN'), ('and', 'CC'), ('subsequent', 'JJ'), ('movie', 'NN'), ('written', 'VBN'), ('by', 'IN'), ('john', 'NN'), ('green', 'NNS'), ('were', 'VBD'), ('inspired', 'VBN'), ('in', 'IN'), ('part', 'NN'), ('by', 'IN'), ('esther', 'DT'), ('earl', 'NN'), ('.', '.'), ('esther', 'CC'), ('earl', 'NN'), ('was', 'VBD'), ('the', 'DT'), ('author', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('friend', 'NN'), ('.', '.'), ('the', 'DT'), ('lead', 'JJ'), ('character', 'NN'), ('hazel', 'NN'), ('in', 'IN'), ('the', 'DT'), ('movie', 'NN'), ('was', 'VBD'), ('inspired', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('author', 'NN'), ('’', 'NNP'), ('s', 'VBZ'), ('friendship', 'NN'), ('with', 'IN'), ('esther', 'DT'), ('earl', 'NN'), ('and', 'CC'), ('his', 'PRP$'), ('affection', 'NN'), ('for', 'IN'), ('her', 'PRP$'), ('family', 'NN'), ('and', 'CC'), ('friends', 'NNS'), ('.', '.'), ('the', 'DT'), ('superficial', 'JJ'), ('concept', 'NN'), ('of', 'IN'), ('oxygen', 'NN'), ('tubes', 'NNS'), ('and', 'CC'), ('thyroid', 'JJ'), ('cancer', 'NN'), ('was', 'VBD'), ('from', 'IN'), ('esther', 'JJ'), ('’', 'NN'), ('s', 'JJ'), ('life', 'NN'), ('.', '.'), ('she', 'PRP'), ('died', 'VBD'), ('of', 'IN'), ('thyroid', 'JJ'), ('cancer', 'NN'), ('on', 'IN'), ('august', 'JJ'), ('25', 'CD'), (',', ','), ('2010', 'CD'), (',', ','), ('at', 'IN'), ('age', 'NN'), ('sixteen', 'NN'), ('.', '.'), ('esther', 'CC'), ('’', 'JJ'), ('s', 'JJ'), ('unusual', 'JJ'), ('mix', 'NN'), ('of', 'IN'), ('teenagers', 'NNS'), ('and', 'CC'), ('empathy', 'JJ'), ('inspired', 'VBD'), ('the', 'DT'), ('author', 'NN'), ('the', 'DT'), ('most', 'RBS'), ('.', '.'), ('she', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('very', 'RB'), ('outwardly', 'RB'), ('focused', 'JJ'), ('person', 'NN'), (',', ','), ('very', 'RB'), ('conscious', 'JJ'), ('of', 'IN'), ('and', 'CC'), ('attentive', 'JJ'), ('to', 'TO'), ('her', 'PRP$'), ('friends', 'NNS'), ('and', 'CC'), ('family', 'NN'), (',', ','), ('but', 'CC'), ('she', 'PRP'), ('was', 'VBD'), ('also', 'RB'), ('silly', 'RB'), ('and', 'CC'), ('funny', 'JJ'), ('and', 'CC'), ('totally', 'RB'), ('normal', 'JJ'), ('.', '.'), ('the', 'DT'), ('author', 'NN'), ('didn', 'NN'), ('’', 'NNP'), ('t', 'NN'), ('appropriate', 'VBP'), ('esther', 'NN'), (\"'s\", 'POS'), ('story', 'NN'), (',', ','), ('which', 'WDT'), ('belongs', 'VBZ'), ('to', 'TO'), ('her', 'PRP$'), ('and', 'CC'), ('to', 'TO'), ('her', 'PRP$'), ('family', 'NN'), ('and', 'CC'), ('not', 'RB'), ('to', 'TO'), ('me', 'PRP'), ('.', '.'), ('hazel', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('fictional', 'JJ'), ('character', 'NN'), (',', ','), ('and', 'CC'), ('she', 'PRP'), ('is', 'VBZ'), ('in', 'IN'), ('many', 'JJ'), ('important', 'JJ'), ('ways', 'NNS'), ('very', 'RB'), ('different', 'JJ'), ('from', 'IN'), ('the', 'DT'), ('person', 'NN'), ('esther', 'DT'), ('was', 'VBD'), ('.', '.')]\n",
            " \n",
            "Count the occurance of the POS:\n",
            "Counter({'NN': 39, 'JJ': 21, 'IN': 17, 'DT': 15, 'CC': 15, 'VBD': 9, '.': 9, 'RB': 8, 'NNS': 7, 'PRP$': 6, ',': 6, 'PRP': 5, 'VBZ': 4, 'TO': 4, 'VBN': 3, 'NNP': 3, 'CD': 2, 'RBS': 1, 'VBP': 1, 'POS': 1, 'WDT': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "fL9tF5u9Op7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CONCEPT: \n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "  \n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i92BWn5V51B",
        "outputId": "e332daab-ea51-4474-d386-960ccb9b3abc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FOR OUR CORPUS\n",
        "\n",
        "for sent in text_tokens:\n",
        "  for word in sent: \n",
        "    print(word, \":\", lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n4E7aEzOsEv",
        "outputId": "06f37da0-e079-4918-d54a-0e6fb88b21f1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the : the\n",
            "fault : fault\n",
            "in : in\n",
            "our : our\n",
            "stars : star\n",
            "book : book\n",
            "and : and\n",
            "subsequent : subsequent\n",
            "movie : movie\n",
            "written : written\n",
            "by : by\n",
            "john : john\n",
            "green : green\n",
            "were : were\n",
            "inspired : inspired\n",
            "in : in\n",
            "part : part\n",
            "by : by\n",
            "esther : esther\n",
            "earl : earl\n",
            ". : .\n",
            "esther : esther\n",
            "earl : earl\n",
            "was : wa\n",
            "the : the\n",
            "author : author\n",
            "’ : ’\n",
            "s : s\n",
            "friend : friend\n",
            ". : .\n",
            "the : the\n",
            "lead : lead\n",
            "character : character\n",
            "hazel : hazel\n",
            "in : in\n",
            "the : the\n",
            "movie : movie\n",
            "was : wa\n",
            "inspired : inspired\n",
            "by : by\n",
            "the : the\n",
            "author : author\n",
            "’ : ’\n",
            "s : s\n",
            "friendship : friendship\n",
            "with : with\n",
            "esther : esther\n",
            "earl : earl\n",
            "and : and\n",
            "his : his\n",
            "affection : affection\n",
            "for : for\n",
            "her : her\n",
            "family : family\n",
            "and : and\n",
            "friends : friend\n",
            ". : .\n",
            "the : the\n",
            "superficial : superficial\n",
            "concept : concept\n",
            "of : of\n",
            "oxygen : oxygen\n",
            "tubes : tube\n",
            "and : and\n",
            "thyroid : thyroid\n",
            "cancer : cancer\n",
            "was : wa\n",
            "from : from\n",
            "esther : esther\n",
            "’ : ’\n",
            "s : s\n",
            "life : life\n",
            ". : .\n",
            "she : she\n",
            "died : died\n",
            "of : of\n",
            "thyroid : thyroid\n",
            "cancer : cancer\n",
            "on : on\n",
            "august : august\n",
            "25 : 25\n",
            ", : ,\n",
            "2010 : 2010\n",
            ", : ,\n",
            "at : at\n",
            "age : age\n",
            "sixteen : sixteen\n",
            ". : .\n",
            "esther : esther\n",
            "’ : ’\n",
            "s : s\n",
            "unusual : unusual\n",
            "mix : mix\n",
            "of : of\n",
            "teenagers : teenager\n",
            "and : and\n",
            "empathy : empathy\n",
            "inspired : inspired\n",
            "the : the\n",
            "author : author\n",
            "the : the\n",
            "most : most\n",
            ". : .\n",
            "she : she\n",
            "was : wa\n",
            "a : a\n",
            "very : very\n",
            "outwardly : outwardly\n",
            "focused : focused\n",
            "person : person\n",
            ", : ,\n",
            "very : very\n",
            "conscious : conscious\n",
            "of : of\n",
            "and : and\n",
            "attentive : attentive\n",
            "to : to\n",
            "her : her\n",
            "friends : friend\n",
            "and : and\n",
            "family : family\n",
            ", : ,\n",
            "but : but\n",
            "she : she\n",
            "was : wa\n",
            "also : also\n",
            "silly : silly\n",
            "and : and\n",
            "funny : funny\n",
            "and : and\n",
            "totally : totally\n",
            "normal : normal\n",
            ". : .\n",
            "the : the\n",
            "author : author\n",
            "didn : didn\n",
            "’ : ’\n",
            "t : t\n",
            "appropriate : appropriate\n",
            "esther : esther\n",
            "'s : 's\n",
            "story : story\n",
            ", : ,\n",
            "which : which\n",
            "belongs : belongs\n",
            "to : to\n",
            "her : her\n",
            "and : and\n",
            "to : to\n",
            "her : her\n",
            "family : family\n",
            "and : and\n",
            "not : not\n",
            "to : to\n",
            "me : me\n",
            ". : .\n",
            "hazel : hazel\n",
            "is : is\n",
            "a : a\n",
            "fictional : fictional\n",
            "character : character\n",
            ", : ,\n",
            "and : and\n",
            "she : she\n",
            "is : is\n",
            "in : in\n",
            "many : many\n",
            "important : important\n",
            "ways : way\n",
            "very : very\n",
            "different : different\n",
            "from : from\n",
            "the : the\n",
            "person : person\n",
            "esther : esther\n",
            "was : wa\n",
            ". : .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop Words "
      ],
      "metadata": {
        "id": "7ARxEywBO1y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "# Example sentence - text, text_tokens \n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "without_stopwords = []\n",
        "\n",
        "for t in text_tokens:\n",
        "  for w in t: \n",
        "    if w not in stop_words: \n",
        "      without_stopwords.append(w)\n",
        "\n",
        "print(without_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtYdGv7eQyp_",
        "outputId": "041b6908-0977-4e8f-bcf6-4393e03a8334"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fault', 'stars', 'book', 'subsequent', 'movie', 'written', 'john', 'green', 'inspired', 'part', 'esther', 'earl', '.', 'esther', 'earl', 'author', '’', 'friend', '.', 'lead', 'character', 'hazel', 'movie', 'inspired', 'author', '’', 'friendship', 'esther', 'earl', 'affection', 'family', 'friends', '.', 'superficial', 'concept', 'oxygen', 'tubes', 'thyroid', 'cancer', 'esther', '’', 'life', '.', 'died', 'thyroid', 'cancer', 'august', '25', ',', '2010', ',', 'age', 'sixteen', '.', 'esther', '’', 'unusual', 'mix', 'teenagers', 'empathy', 'inspired', 'author', '.', 'outwardly', 'focused', 'person', ',', 'conscious', 'attentive', 'friends', 'family', ',', 'also', 'silly', 'funny', 'totally', 'normal', '.', 'author', '’', 'appropriate', 'esther', \"'s\", 'story', ',', 'belongs', 'family', '.', 'hazel', 'fictional', 'character', ',', 'many', 'important', 'ways', 'different', 'person', 'esther', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming "
      ],
      "metadata": {
        "id": "GFF-NAnqSpmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        "ps = PorterStemmer()\n",
        "\n",
        "words = [\"program\", \"programs\", \"programmer\", \"programming\", \"programmers\"]\n",
        "  \n",
        "for w in words:\n",
        "    print(w, \" : \", ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd4DPZucSq6K",
        "outputId": "ce82f7ec-e94e-4b42-d857-5801cbd8015e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programmer  :  programm\n",
            "programming  :  program\n",
            "programmers  :  programm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in text_tokens:\n",
        "  for word in sent: \n",
        "    print(word, \":\", ps.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBRNGzwGWbDM",
        "outputId": "56012bc1-a43b-4561-fb85-1566aa135748"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the : the\n",
            "fault : fault\n",
            "in : in\n",
            "our : our\n",
            "stars : star\n",
            "book : book\n",
            "and : and\n",
            "subsequent : subsequ\n",
            "movie : movi\n",
            "written : written\n",
            "by : by\n",
            "john : john\n",
            "green : green\n",
            "were : were\n",
            "inspired : inspir\n",
            "in : in\n",
            "part : part\n",
            "by : by\n",
            "esther : esther\n",
            "earl : earl\n",
            ". : .\n",
            "esther : esther\n",
            "earl : earl\n",
            "was : wa\n",
            "the : the\n",
            "author : author\n",
            "’ : ’\n",
            "s : s\n",
            "friend : friend\n",
            ". : .\n",
            "the : the\n",
            "lead : lead\n",
            "character : charact\n",
            "hazel : hazel\n",
            "in : in\n",
            "the : the\n",
            "movie : movi\n",
            "was : wa\n",
            "inspired : inspir\n",
            "by : by\n",
            "the : the\n",
            "author : author\n",
            "’ : ’\n",
            "s : s\n",
            "friendship : friendship\n",
            "with : with\n",
            "esther : esther\n",
            "earl : earl\n",
            "and : and\n",
            "his : hi\n",
            "affection : affect\n",
            "for : for\n",
            "her : her\n",
            "family : famili\n",
            "and : and\n",
            "friends : friend\n",
            ". : .\n",
            "the : the\n",
            "superficial : superfici\n",
            "concept : concept\n",
            "of : of\n",
            "oxygen : oxygen\n",
            "tubes : tube\n",
            "and : and\n",
            "thyroid : thyroid\n",
            "cancer : cancer\n",
            "was : wa\n",
            "from : from\n",
            "esther : esther\n",
            "’ : ’\n",
            "s : s\n",
            "life : life\n",
            ". : .\n",
            "she : she\n",
            "died : die\n",
            "of : of\n",
            "thyroid : thyroid\n",
            "cancer : cancer\n",
            "on : on\n",
            "august : august\n",
            "25 : 25\n",
            ", : ,\n",
            "2010 : 2010\n",
            ", : ,\n",
            "at : at\n",
            "age : age\n",
            "sixteen : sixteen\n",
            ". : .\n",
            "esther : esther\n",
            "’ : ’\n",
            "s : s\n",
            "unusual : unusu\n",
            "mix : mix\n",
            "of : of\n",
            "teenagers : teenag\n",
            "and : and\n",
            "empathy : empathi\n",
            "inspired : inspir\n",
            "the : the\n",
            "author : author\n",
            "the : the\n",
            "most : most\n",
            ". : .\n",
            "she : she\n",
            "was : wa\n",
            "a : a\n",
            "very : veri\n",
            "outwardly : outwardli\n",
            "focused : focus\n",
            "person : person\n",
            ", : ,\n",
            "very : veri\n",
            "conscious : consciou\n",
            "of : of\n",
            "and : and\n",
            "attentive : attent\n",
            "to : to\n",
            "her : her\n",
            "friends : friend\n",
            "and : and\n",
            "family : famili\n",
            ", : ,\n",
            "but : but\n",
            "she : she\n",
            "was : wa\n",
            "also : also\n",
            "silly : silli\n",
            "and : and\n",
            "funny : funni\n",
            "and : and\n",
            "totally : total\n",
            "normal : normal\n",
            ". : .\n",
            "the : the\n",
            "author : author\n",
            "didn : didn\n",
            "’ : ’\n",
            "t : t\n",
            "appropriate : appropri\n",
            "esther : esther\n",
            "'s : 's\n",
            "story : stori\n",
            ", : ,\n",
            "which : which\n",
            "belongs : belong\n",
            "to : to\n",
            "her : her\n",
            "and : and\n",
            "to : to\n",
            "her : her\n",
            "family : famili\n",
            "and : and\n",
            "not : not\n",
            "to : to\n",
            "me : me\n",
            ". : .\n",
            "hazel : hazel\n",
            "is : is\n",
            "a : a\n",
            "fictional : fiction\n",
            "character : charact\n",
            ", : ,\n",
            "and : and\n",
            "she : she\n",
            "is : is\n",
            "in : in\n",
            "many : mani\n",
            "important : import\n",
            "ways : way\n",
            "very : veri\n",
            "different : differ\n",
            "from : from\n",
            "the : the\n",
            "person : person\n",
            "esther : esther\n",
            "was : wa\n",
            ". : .\n"
          ]
        }
      ]
    }
  ]
}